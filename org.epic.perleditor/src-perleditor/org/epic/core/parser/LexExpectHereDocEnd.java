// $ANTLR : "expectHereDocEnd.g" -> "LexExpectHereDocEnd.java"$

// This source file was generated by ANTLR. Do not edit manually!
package org.epic.core.parser;

import java.io.InputStream;
import java.io.Reader;
import java.util.Hashtable;

import antlr.ByteBuffer;
import antlr.CharBuffer;
import antlr.CharStreamException;
import antlr.CharStreamIOException;
import antlr.InputBuffer;
import antlr.LexerSharedInputState;
import antlr.NoViableAltForCharException;
import antlr.RecognitionException;
import antlr.Token;
import antlr.TokenStream;
import antlr.TokenStreamException;
import antlr.TokenStreamIOException;
import antlr.TokenStreamRecognitionException;
import antlr.collections.impl.BitSet;

public class LexExpectHereDocEnd extends org.epic.core.parser.LexExpectHereDocEndBase implements LexExpectHereDocEndTokenTypes, TokenStream
 {

	private boolean endOfHeredoc;
	
	public void setInputState(LexerSharedInputState state)
    {
        super.setInputState(state);
        endOfHeredoc = false;
    }
public LexExpectHereDocEnd(InputStream in) {
	this(new ByteBuffer(in));
}
public LexExpectHereDocEnd(Reader in) {
	this(new CharBuffer(in));
}
public LexExpectHereDocEnd(InputBuffer ib) {
	this(new LexerSharedInputState(ib));
}
public LexExpectHereDocEnd(LexerSharedInputState state) {
	super(state);
	caseSensitiveLiterals = true;
	setCaseSensitive(true);
	literals = new Hashtable();
}

public Token nextToken() throws TokenStreamException {
	Token theRetToken=null;
tryAgain:
	for (;;) {
		Token _token = null;
		int _ttype = Token.INVALID_TYPE;
		resetText();
		try {   // for char stream error handling
			try {   // for lexical error handling
				if ((_tokenSet_0.member(LA(1)))) {
					mCLOSE_HEREDOC(true);
					theRetToken=_returnToken;
				}
				else {
					if (LA(1)==EOF_CHAR) {uponEOF(); _returnToken = makeToken(Token.EOF_TYPE);}
				else {throw new NoViableAltForCharException((char)LA(1), getFilename(), getLine(), getColumn());}
				}
				
				if ( _returnToken==null ) continue tryAgain; // found SKIP token
				_ttype = _returnToken.getType();
				_ttype = testLiteralsTable(_ttype);
				_returnToken.setType(_ttype);
				return _returnToken;
			}
			catch (RecognitionException e) {
				throw new TokenStreamRecognitionException(e);
			}
		}
		catch (CharStreamException cse) {
			if ( cse instanceof CharStreamIOException ) {
				throw new TokenStreamIOException(((CharStreamIOException)cse).io);
			}
			else {
				throw new TokenStreamException(cse.getMessage());
			}
		}
	}
}

	public final void mCLOSE_HEREDOC(boolean _createToken) throws RecognitionException, CharStreamException, TokenStreamException {
		int _ttype; Token _token=null; int _begin=text.length();
		_ttype = CLOSE_HEREDOC;
		int _saveIndex;
		
		{
		int _cnt580=0;
		_loop580:
		do {
			if ((_tokenSet_0.member(LA(1)))) {
				mHEREDOC_LINE(false);
				if (endOfHeredoc) break;
			}
			else {
				if ( _cnt580>=1 ) { break _loop580; } else {throw new NoViableAltForCharException((char)LA(1), getFilename(), getLine(), getColumn());}
			}
			
			_cnt580++;
		} while (true);
		}
		
				endOfHeredoc = false;
				getParent().pop();
			
		if ( _createToken && _token==null && _ttype!=Token.SKIP ) {
			_token = makeToken(_ttype);
			_token.setText(new String(text.getBuffer(), _begin, text.length()-_begin));
		}
		_returnToken = _token;
	}
	
	protected final void mHEREDOC_LINE(boolean _createToken) throws RecognitionException, CharStreamException, TokenStreamException {
		int _ttype; Token _token=null; int _begin=text.length();
		_ttype = HEREDOC_LINE;
		int _saveIndex;
		Token t=null;
		
		mHEREDOC_LINE_CHARS(true);
		t=_returnToken;
		{
		switch ( LA(1)) {
		case '\n':  case '\r':
		{
			mNEWLINE(false);
			endOfHeredoc = terminator.equals(t.getText()) || maxLinesExceeded();
			break;
		}
		case '\uffff':
		{
			_saveIndex=text.length();
			match('\uFFFF');
			text.setLength(_saveIndex);
			endOfHeredoc = true;
			break;
		}
		default:
		{
			throw new NoViableAltForCharException((char)LA(1), getFilename(), getLine(), getColumn());
		}
		}
		}
		if ( _createToken && _token==null && _ttype!=Token.SKIP ) {
			_token = makeToken(_ttype);
			_token.setText(new String(text.getBuffer(), _begin, text.length()-_begin));
		}
		_returnToken = _token;
	}
	
	protected final void mHEREDOC_LINE_CHARS(boolean _createToken) throws RecognitionException, CharStreamException, TokenStreamException {
		int _ttype; Token _token=null; int _begin=text.length();
		_ttype = HEREDOC_LINE_CHARS;
		int _saveIndex;
		
		{
		_loop585:
		do {
			if ((_tokenSet_1.member(LA(1)))) {
				mNOTNEWLINE(false);
			}
			else {
				break _loop585;
			}
			
		} while (true);
		}
		if ( _createToken && _token==null && _ttype!=Token.SKIP ) {
			_token = makeToken(_ttype);
			_token.setText(new String(text.getBuffer(), _begin, text.length()-_begin));
		}
		_returnToken = _token;
	}
	
	protected final void mNEWLINE(boolean _createToken) throws RecognitionException, CharStreamException, TokenStreamException {
		int _ttype; Token _token=null; int _begin=text.length();
		_ttype = NEWLINE;
		int _saveIndex;
		
		{
		if ((LA(1)=='\r') && (LA(2)=='\n')) {
			match('\r');
			match('\n');
		}
		else if ((LA(1)=='\r') && (true)) {
			match('\r');
		}
		else if ((LA(1)=='\n')) {
			match('\n');
		}
		else {
			throw new NoViableAltForCharException((char)LA(1), getFilename(), getLine(), getColumn());
		}
		
		}
		newline();
		if ( _createToken && _token==null && _ttype!=Token.SKIP ) {
			_token = makeToken(_ttype);
			_token.setText(new String(text.getBuffer(), _begin, text.length()-_begin));
		}
		_returnToken = _token;
	}
	
	protected final void mNOTNEWLINE(boolean _createToken) throws RecognitionException, CharStreamException, TokenStreamException {
		int _ttype; Token _token=null; int _begin=text.length();
		_ttype = NOTNEWLINE;
		int _saveIndex;
		
		{
		match(_tokenSet_1);
		}
		if ( _createToken && _token==null && _ttype!=Token.SKIP ) {
			_token = makeToken(_ttype);
			_token.setText(new String(text.getBuffer(), _begin, text.length()-_begin));
		}
		_returnToken = _token;
	}
	
	
	private static final long[] mk_tokenSet_0() {
		long[] data = new long[2048];
		for (int i = 0; i<=8; i++) { data[i]=-1L; }
		data[9]=65535L;
		data[1023]=-9223372036854775808L;
		return data;
	}
	public static final BitSet _tokenSet_0 = new BitSet(mk_tokenSet_0());
	private static final long[] mk_tokenSet_1() {
		long[] data = new long[2048];
		data[0]=-9217L;
		for (int i = 1; i<=8; i++) { data[i]=-1L; }
		data[9]=65535L;
		return data;
	}
	public static final BitSet _tokenSet_1 = new BitSet(mk_tokenSet_1());
	
	}
